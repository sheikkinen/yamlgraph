# Showcase Pipeline - YAML Graph Definition
# Replaces Python-defined graph in builder.py

version: "1.0"
name: showcase
description: Content generation pipeline (generate → analyze → summarize)

defaults:
  provider: mistral
  temperature: 0.7

nodes:
  generate:
    type: llm
    prompt: generate
    # output_model now defined inline in prompt YAML
    temperature: 0.8
    on_error: fallback        # skip | retry | fail | fallback
    fallback:
      provider: anthropic    # Fallback provider if primary fails
    variables:
      topic: "{state.topic}"
      word_count: "{state.word_count}"
      style: "{state.style}"
    state_key: generated

  analyze:
    type: llm
    prompt: analyze
    # output_model now defined inline in prompt YAML
    temperature: 0.3
    variables:
      content: "{state.generated.content}"
    state_key: analysis
    requires: [generated]

  summarize:
    type: llm
    prompt: summarize
    # No structured output - returns raw string
    temperature: 0.5
    variables:
      topic: "{state.topic}"
      generated_content: "{state.generated.content}"
      analysis_summary: "{state.analysis.summary}"
      key_points: "{state.analysis.key_points}"
      sentiment: "{state.analysis.sentiment}"
    state_key: final_summary
    requires: [generated, analysis]

edges:
  - from: START
    to: generate

  - from: generate
    to: analyze
    condition: continue

  - from: generate
    to: END
    condition: end

  - from: analyze
    to: summarize

  - from: summarize
    to: END

# Note: Routing conditions are handled by _should_continue() in graph_loader.py
# Condition names 'continue' and 'end' map to that function's return values
